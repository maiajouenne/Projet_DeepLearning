{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-28 13:58:34.049349: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-28 13:58:34.256946: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-28 13:58:34.256990: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-28 13:58:34.285542: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-28 13:58:34.349102: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-28 13:58:35.015135: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import cv2\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import imblearn\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_crop(path):\n",
    "    \n",
    "    # Read the CSV file into a DataFrame\n",
    "    if path[-1] == '/':\n",
    "        df = pd.read_csv(path +'_annotations.csv')\n",
    "    else :\n",
    "        df = pd.read_csv(path +'/_annotations.csv')\n",
    "\n",
    "    # Read and store cropped images\n",
    "    cropped_image_list = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        image_path = row['filename']\n",
    "        if path[-1] == '/':\n",
    "            image = Image.open(path + image_path)\n",
    "        else :\n",
    "            image = Image.open(path + '/' + image_path)\n",
    "            \n",
    "\n",
    "        # Extract cropping coordinates\n",
    "        xmin, ymin, xmax, ymax = (\n",
    "            max(0, row['xmin']),\n",
    "            max(0, row['ymin']),\n",
    "            min(image.width, row['xmax']),\n",
    "            min(image.height, row['ymax'])\n",
    "        )\n",
    "\n",
    "        # Check if the adjusted coordinates are valid\n",
    "        if xmin < xmax and ymin < ymax:\n",
    "            \n",
    "            # Crop the image\n",
    "            cropped_image = np.array(image.crop((xmin, ymin, xmax, ymax))) \n",
    "\n",
    "            # Reshape the images in the 'cropped_image' column\n",
    "            cropped_reshape_image = cv2.resize(cropped_image, (171, 138))\n",
    "\n",
    "            # Store the cropped image in the list\n",
    "            cropped_image_list.append(cropped_reshape_image)\n",
    "        else:\n",
    "            # If the coordinates are invalid, append a placeholder (e.g., None)\n",
    "            cropped_image_list.append(None)\n",
    "\n",
    "    # Add a new column to the DataFrame with cropped images\n",
    "    df['cropped_image'] = cropped_image_list.copy()\n",
    "\n",
    "    # Filter out rows with None values in the 'cropped_image' column\n",
    "    df_valid_crops = df.dropna(subset=['cropped_image']).copy()\n",
    "    \n",
    "    df_final = df_valid_crops[['class', 'cropped_image']].copy()\n",
    "    \n",
    "    # \n",
    "    old_class_to_actual_class = {\n",
    "        'tuna' : 'tuna', \n",
    "        'surgeon': 'surgeon', \n",
    "        'shark': 'shark', \n",
    "        'jack': 'jack', \n",
    "        'grouper': 'grouper', \n",
    "        'parrot': 'parrot', \n",
    "        'snapper': 'snapper',\n",
    "        'damsel': 'damsel', \n",
    "        'trigger': 'trigger', \n",
    "        'Zanclidae (Moorish Idol)': 'moorish idol',\n",
    "        'Scaridae -Parrotfishes-': 'parrot', \n",
    "        'Carangidae -Jacks-': 'jack',\n",
    "        'Scombridae -Tunas-': 'tuna', \n",
    "        'Shark -Selachimorpha-': 'shark',\n",
    "        'Serranidae -Groupers-': 'grouper', \n",
    "        'Lutjanidae -Snappers-': 'snapper',\n",
    "        'Acanthuridae -Surgeonfishes-': 'surgeon', \n",
    "        'Pomacentridae -Damselfishes-': 'damsel',\n",
    "        'Labridae -Wrasse-': 'wrasse', \n",
    "        'angel': 'angel', \n",
    "        'wrasse': 'wrasse', \n",
    "        'Zanclidae -Moorish Idol-': 'moorish idol',\n",
    "        'Ephippidae -Spadefishes-': 'spade', \n",
    "        'Pomacanthidae -Angelfishes-': 'angel',\n",
    "        'Balistidae -Triggerfishes-': 'trigger', \n",
    "        'spade': 'spade'\n",
    "    }\n",
    "   \n",
    "    # Replace old class names with new class names\n",
    "    df_final['class'] = df_final['class'].replace(old_class_to_actual_class)\n",
    "    \n",
    "    return df_final\n",
    "\n",
    "\n",
    "def print_image_by_classes(df,images_to_plot=2):\n",
    "    \n",
    "    # Get unique classes in the DataFrame\n",
    "    unique_classes = df['class'].unique()\n",
    "\n",
    "    # Plot two random images for each class\n",
    "    for class_name in unique_classes:\n",
    "        # Filter DataFrame based on the current class\n",
    "        df_same_class = df[df['class'] == class_name]\n",
    "\n",
    "        # Check the number of images in the current class\n",
    "        num_images = len(df_same_class)\n",
    "\n",
    "        if num_images >= images_to_plot:\n",
    "            # Randomly select two images from the current class\n",
    "            random_indices = random.sample(df_same_class.index.tolist(), images_to_plot)\n",
    "\n",
    "            # Plot the two random images for the current class\n",
    "            fig, axes = plt.subplots(1, images_to_plot, figsize=(10, 5))\n",
    "            fig.suptitle(f'Two Random Images of Class: {class_name}')\n",
    "\n",
    "            for i, ax in enumerate(axes):\n",
    "                ax.imshow(df_same_class.loc[random_indices[i]]['cropped_image'])\n",
    "                ax.set_title(f\"Index: {random_indices[i]}\")\n",
    "                ax.axis('off')\n",
    "\n",
    "            plt.show()\n",
    "            continue\n",
    "            \n",
    "        elif num_images >= 1:\n",
    "            # Plot the single image for the current class\n",
    "            plt.figure(figsize=(5, 5))\n",
    "            plt.imshow(df_same_class.iloc[0]['cropped_image'])\n",
    "            plt.title(f'Image of Class: {class_name} (Index: {df_same_class.index[0]})')\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "            continue\n",
    "            \n",
    "        else:\n",
    "            print(f\"No images of class '{class_name}' for plotting.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = read_and_crop('data/train/')\n",
    "df_test = read_and_crop('data/test/')\n",
    "df_valid = read_and_crop('data/valid/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to ressort the X and y of dataframe\n",
    "def to_work(df):\n",
    "    \n",
    "    class_to_number = {\n",
    "    'tuna': 0, \n",
    "    'surgeon': 1, \n",
    "    'shark': 2, \n",
    "    'jack': 3, \n",
    "    'grouper': 4, \n",
    "    'parrot': 5, \n",
    "    'snapper': 6,\n",
    "    'damsel': 7, \n",
    "    'trigger': 8, \n",
    "    'moorish idol': 9, \n",
    "    'wrasse': 10, \n",
    "    'angel': 11, \n",
    "    'spade': 12\n",
    "}\n",
    "\n",
    "    X = np.stack(df['cropped_image'].to_numpy().copy(), axis=0)\n",
    "    \n",
    "    # standardize and center data (make my pc crash)\n",
    "    X = (X / 255) - 0.5\n",
    "    \n",
    "    y = df['class'].replace(class_to_number).to_numpy().copy()\n",
    "    y_cat = to_categorical(y, num_classes=13)  \n",
    "    \n",
    "    return X, y, y_cat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_150563/3044088646.py:25: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  y = df['class'].replace(class_to_number).to_numpy().copy()\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, y_train_cat = to_work(df_train)\n",
    "X_test, y_test, y_test_cat = to_work(df_test)\n",
    "X_val, y_val, y_val_cat = to_work(df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2075, 138, 171, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2075,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def over_undersampling(X, y, st=376):\n",
    "    \n",
    "    # Reshape each image to a flat vector\n",
    "    X_flat = X.reshape(X.shape[0], -1)\n",
    "\n",
    "        # summarize class distribution\n",
    "    print(f\"Original class distribution: {Counter(y)}\")\n",
    "\n",
    "    oversample = RandomOverSampler(sampling_strategy={7:st,8:st,9:st,10:st,11:st,12:st})\n",
    "    undersample = RandomUnderSampler(sampling_strategy={1:st})\n",
    "\n",
    "        # Fit and apply the transform\n",
    "    X_over, y_over = oversample.fit_resample(X_flat, y)\n",
    "    X_under, y_under = undersample.fit_resample(X_over, y_over)\n",
    "        # Summarize class distribution after oversampling\n",
    "    print(f\"Class distribution after sampling: {Counter(y_under)}\")\n",
    "\n",
    "        # Reshape the resampled data back to the original image shape\n",
    "    X_resampled = X_under.reshape(-1, 138, 171, 3)\n",
    "    X, y = X_resampled, y_under\n",
    "\n",
    "    return X_resampled, y_under\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution: Counter({1: 534, 3: 376, 0: 333, 6: 299, 2: 188, 5: 176, 4: 147, 7: 12, 8: 2, 9: 2, 10: 2, 11: 2, 12: 2})\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "X_resampled, y_resampled = over_undersampling(X_train, y_train, st=376)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model():\n",
    "    \n",
    "    # Start by creating a sequential model\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    ### First Convolution & MaxPooling\n",
    "    model.add(layers.Conv2D(8, (4, 4), activation='relu', padding='same', input_shape=(138, 171, 3)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    ### Second Convolution & MaxPoolingialize\n",
    "    model.add(layers.Conv2D(16, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    ### Flattening\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    ### One Fully Connected layer\n",
    "    model.add(layers.Dense(25, activation='relu'))\n",
    "    # droupout to minimise the overfitting\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    ### Last layer - Classification Layer\n",
    "    model.add(layers.Dense(13, activation='softmax')) # softmax for multiclass classification\n",
    "\n",
    "    ### Model compilation\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy', 'Precision','Recall'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to plot the result\n",
    "def plot_history(history):\n",
    "    fig, axs = plt.subplots(4,1, figsize=(10,10))\n",
    "    \n",
    "    axs[0].plot(history.history['loss'], color='red', label='train')\n",
    "    axs[0].plot(history.history['val_loss'], color='blue', label='val')\n",
    "    axs[0].set_title('Loss')\n",
    "    axs[0].legend(['train', 'validation'],loc=\"upper right\")\n",
    "    \n",
    "    axs[1].plot(history.history['accuracy'], color='red', label='train')\n",
    "    axs[1].plot(history.history['val_accuracy'], color='blue', label='val')\n",
    "    axs[1].set_title('Accuracy ')\n",
    "    axs[1].legend(['train', 'validation'],loc=\"upper right\")\n",
    "\n",
    "    axs[2].plot(history.history['precision'], color='red', label='train')\n",
    "    axs[2].plot(history.history['val_precision'], color='blue', label='val')\n",
    "    axs[2].set_title('Precision ')\n",
    "    axs[2].legend(['train', 'validation'],loc=\"upper right\")\n",
    "\n",
    "    axs[3].plot(history.history['recall'], color='red', label='train')\n",
    "    axs[3].plot(history.history['val_recall'], color='blue', label='val')\n",
    "    axs[3].set_title('Recall')\n",
    "    axs[3].legend(['train', 'validation'],loc=\"upper right\")\n",
    "    \n",
    "\n",
    "    for ax in axs.flat:\n",
    "        ax.set(xlabel='Epoch', ylabel='')\n",
    "\n",
    "    # Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "    for ax in axs.flat:\n",
    "        ax.label_outer()\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_resampled_cat=to_categorical(y_resampled, num_classes=13) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save the models & the metrics\n",
    "models_cnn = {}\n",
    "\n",
    "# early stopping critera\n",
    "es = EarlyStopping(patience=20, restore_best_weights=True)\n",
    "\n",
    "for batch in [4,16,32,64,128,256] :\n",
    "    \n",
    "    model = init_model()\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_resampled,\n",
    "        y_resampled_cat,\n",
    "        validation_data=(X_val, y_val_cat),\n",
    "        epochs = 100,\n",
    "        batch_size = batch, \n",
    "        verbose = 0, \n",
    "        callbacks = [es]\n",
    "    )\n",
    "    \n",
    "    print(f'------------------------------------------Batch Size {batch}------------------------------------------')\n",
    "    \n",
    "    # store the model\n",
    "    models_cnn[batch] = model\n",
    "        \n",
    "    # plot the history of loss and accuracy\n",
    "    plot_history(history)\n",
    "    \n",
    "    # print the evaluation of the model:\n",
    "    trainEval = model.evaluate(X_resampled,y_resampled_cat, verbose=0)\n",
    "    valEval = model.evaluate(X_val,y_val_cat, verbose=0)\n",
    "\n",
    "    print(\"         Model Evaluation on Training :\")\n",
    "    print(\"     Training Loss:    \", trainEval[0])\n",
    "    print(\"   Training Accuracy:  \", trainEval[1])\n",
    "    print(\"  Training Precision:  \", trainEval[2])\n",
    "    print(\"    Training Recall:   \", trainEval[3], '\\n')\n",
    "    print(\"         Model Evaluation on Validation :\")\n",
    "    print(\"    Validation Loss:   \", valEval[0])\n",
    "    print(\"  Validation Accuracy: \", valEval[1])\n",
    "    print(\" Validation Precision: \", valEval[2])\n",
    "    print(\"   Validation Recall:  \", valEval[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
