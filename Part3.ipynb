{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/todin/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n",
      "2024-02-28 12:15:09.826597: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-28 12:15:09.911170: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-28 12:15:09.912249: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-28 12:15:11.308173: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import cv2\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import imblearn\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_crop(path):\n",
    "    \n",
    "    # Read the CSV file into a DataFrame\n",
    "    if path[-1] == '/':\n",
    "        df = pd.read_csv(path +'_annotations.csv')\n",
    "    else :\n",
    "        df = pd.read_csv(path +'/_annotations.csv')\n",
    "\n",
    "    # Read and store cropped images\n",
    "    cropped_image_list = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        image_path = row['filename']\n",
    "        if path[-1] == '/':\n",
    "            image = Image.open(path + image_path)\n",
    "        else :\n",
    "            image = Image.open(path + '/' + image_path)\n",
    "            \n",
    "\n",
    "        # Extract cropping coordinates\n",
    "        xmin, ymin, xmax, ymax = (\n",
    "            max(0, row['xmin']),\n",
    "            max(0, row['ymin']),\n",
    "            min(image.width, row['xmax']),\n",
    "            min(image.height, row['ymax'])\n",
    "        )\n",
    "\n",
    "        # Check if the adjusted coordinates are valid\n",
    "        if xmin < xmax and ymin < ymax:\n",
    "            \n",
    "            # Crop the image\n",
    "            cropped_image = np.array(image.crop((xmin, ymin, xmax, ymax))) \n",
    "\n",
    "            # Reshape the images in the 'cropped_image' column\n",
    "            cropped_reshape_image = cv2.resize(cropped_image, (171, 138))\n",
    "\n",
    "            # Store the cropped image in the list\n",
    "            cropped_image_list.append(cropped_reshape_image)\n",
    "        else:\n",
    "            # If the coordinates are invalid, append a placeholder (e.g., None)\n",
    "            cropped_image_list.append(None)\n",
    "\n",
    "    # Add a new column to the DataFrame with cropped images\n",
    "    df['cropped_image'] = cropped_image_list.copy()\n",
    "\n",
    "    # Filter out rows with None values in the 'cropped_image' column\n",
    "    df_valid_crops = df.dropna(subset=['cropped_image']).copy()\n",
    "    \n",
    "    df_final = df_valid_crops[['class', 'cropped_image']].copy()\n",
    "    \n",
    "    # \n",
    "    old_class_to_actual_class = {\n",
    "        'tuna' : 'tuna', \n",
    "        'surgeon': 'surgeon', \n",
    "        'shark': 'shark', \n",
    "        'jack': 'jack', \n",
    "        'grouper': 'grouper', \n",
    "        'parrot': 'parrot', \n",
    "        'snapper': 'snapper',\n",
    "        'damsel': 'damsel', \n",
    "        'trigger': 'trigger', \n",
    "        'Zanclidae (Moorish Idol)': 'moorish idol',\n",
    "        'Scaridae -Parrotfishes-': 'parrot', \n",
    "        'Carangidae -Jacks-': 'jack',\n",
    "        'Scombridae -Tunas-': 'tuna', \n",
    "        'Shark -Selachimorpha-': 'shark',\n",
    "        'Serranidae -Groupers-': 'grouper', \n",
    "        'Lutjanidae -Snappers-': 'snapper',\n",
    "        'Acanthuridae -Surgeonfishes-': 'surgeon', \n",
    "        'Pomacentridae -Damselfishes-': 'damsel',\n",
    "        'Labridae -Wrasse-': 'wrasse', \n",
    "        'angel': 'angel', \n",
    "        'wrasse': 'wrasse', \n",
    "        'Zanclidae -Moorish Idol-': 'moorish idol',\n",
    "        'Ephippidae -Spadefishes-': 'spade', \n",
    "        'Pomacanthidae -Angelfishes-': 'angel',\n",
    "        'Balistidae -Triggerfishes-': 'trigger', \n",
    "        'spade': 'spade'\n",
    "    }\n",
    "   \n",
    "    # Replace old class names with new class names\n",
    "    df_final['class'] = df_final['class'].replace(old_class_to_actual_class)\n",
    "    \n",
    "    return df_final\n",
    "\n",
    "\n",
    "def print_image_by_classes(df,images_to_plot=2):\n",
    "    \n",
    "    # Get unique classes in the DataFrame\n",
    "    unique_classes = df['class'].unique()\n",
    "\n",
    "    # Plot two random images for each class\n",
    "    for class_name in unique_classes:\n",
    "        # Filter DataFrame based on the current class\n",
    "        df_same_class = df[df['class'] == class_name]\n",
    "\n",
    "        # Check the number of images in the current class\n",
    "        num_images = len(df_same_class)\n",
    "\n",
    "        if num_images >= images_to_plot:\n",
    "            # Randomly select two images from the current class\n",
    "            random_indices = random.sample(df_same_class.index.tolist(), images_to_plot)\n",
    "\n",
    "            # Plot the two random images for the current class\n",
    "            fig, axes = plt.subplots(1, images_to_plot, figsize=(10, 5))\n",
    "            fig.suptitle(f'Two Random Images of Class: {class_name}')\n",
    "\n",
    "            for i, ax in enumerate(axes):\n",
    "                ax.imshow(df_same_class.loc[random_indices[i]]['cropped_image'])\n",
    "                ax.set_title(f\"Index: {random_indices[i]}\")\n",
    "                ax.axis('off')\n",
    "\n",
    "            plt.show()\n",
    "            continue\n",
    "            \n",
    "        elif num_images >= 1:\n",
    "            # Plot the single image for the current class\n",
    "            plt.figure(figsize=(5, 5))\n",
    "            plt.imshow(df_same_class.iloc[0]['cropped_image'])\n",
    "            plt.title(f'Image of Class: {class_name} (Index: {df_same_class.index[0]})')\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "            continue\n",
    "            \n",
    "        else:\n",
    "            print(f\"No images of class '{class_name}' for plotting.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = read_and_crop('data/train/')\n",
    "df_test = read_and_crop('data/test/')\n",
    "df_valid = read_and_crop('data/valid/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to ressort the X and y of dataframe\n",
    "def to_work(df):\n",
    "    \n",
    "    class_to_number = {\n",
    "    'tuna': 0, \n",
    "    'surgeon': 1, \n",
    "    'shark': 2, \n",
    "    'jack': 3, \n",
    "    'grouper': 4, \n",
    "    'parrot': 5, \n",
    "    'snapper': 6,\n",
    "    'damsel': 7, \n",
    "    'trigger': 8, \n",
    "    'moorish idol': 9, \n",
    "    'wrasse': 10, \n",
    "    'angel': 11, \n",
    "    'spade': 12\n",
    "}\n",
    "\n",
    "    X = np.stack(df['cropped_image'].to_numpy().copy(), axis=0)\n",
    "    \n",
    "    # standardize and center data (make my pc crash)\n",
    "    X = (X / 255) - 0.5\n",
    "    \n",
    "    y = df['class'].replace(class_to_number).to_numpy().copy()\n",
    "    y_cat = to_categorical(y, num_classes=13)  \n",
    "    \n",
    "    return X, y, y_cat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, y_train_cat = to_work(df_train)\n",
    "X_test, y_test, y_test_cat = to_work(df_test)\n",
    "X_val, y_val, y_val_cat = to_work(df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2075, 138, 171, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2075,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def over_undersampling(X, y, st=376):\n",
    "    \n",
    "    # Reshape each image to a flat vector\n",
    "    X_flat = X.reshape(X.shape[0], -1)\n",
    "\n",
    "        # summarize class distribution\n",
    "    print(f\"Original class distribution: {Counter(y)}\")\n",
    "\n",
    "    oversample = RandomOverSampler(sampling_strategy={7:st,8:st,9:st,10:st,11:st,12:st})\n",
    "    undersample = RandomUnderSampler(sampling_strategy={1:st})\n",
    "\n",
    "        # Fit and apply the transform\n",
    "    X_over, y_over = oversample.fit_resample(X_flat, y)\n",
    "    X_under, y_under = undersample.fit_resample(X_over, y_over)\n",
    "        # Summarize class distribution after oversampling\n",
    "    print(f\"Class distribution after sampling: {Counter(y_under)}\")\n",
    "\n",
    "        # Reshape the resampled data back to the original image shape\n",
    "    X_resampled = X_under.reshape(-1, 138, 171, 3)\n",
    "    X, y = X_resampled, y_under\n",
    "\n",
    "    return X_resampled, y_under\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution: Counter({1: 534, 3: 376, 0: 333, 6: 299, 2: 188, 5: 176, 4: 147, 7: 12, 8: 2, 9: 2, 10: 2, 11: 2, 12: 2})\n"
     ]
    }
   ],
   "source": [
    "X_resampled, y_resampled = over_undersampling(X_train, y_train, st=376)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model():\n",
    "    \n",
    "    # Start by creating a sequential model\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    ### First Convolution & MaxPooling\n",
    "    model.add(layers.Conv2D(8, (4, 4), activation='relu', padding='same', input_shape=(138, 171, 3)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    ### Second Convolution & MaxPoolingialize\n",
    "    model.add(layers.Conv2D(16, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    ### Flattening\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    ### One Fully Connected layer\n",
    "    model.add(layers.Dense(25, activation='relu'))\n",
    "    # droupout to minimise the overfitting\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    ### Last layer - Classification Layer\n",
    "    model.add(layers.Dense(13, activation='softmax')) # softmax for multiclass classification\n",
    "\n",
    "    ### Model compilation\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy', 'Precision','Recall'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to plot the result\n",
    "def plot_history(history):\n",
    "    fig, axs = plt.subplots(4,1, figsize=(10,10))\n",
    "    \n",
    "    axs[0].plot(history.history['loss'], color='red', label='train')\n",
    "    axs[0].plot(history.history['val_loss'], color='blue', label='val')\n",
    "    axs[0].set_title('Loss')\n",
    "    axs[0].legend(['train', 'validation'],loc=\"upper right\")\n",
    "    \n",
    "    axs[1].plot(history.history['accuracy'], color='red', label='train')\n",
    "    axs[1].plot(history.history['val_accuracy'], color='blue', label='val')\n",
    "    axs[1].set_title('Accuracy ')\n",
    "    axs[1].legend(['train', 'validation'],loc=\"upper right\")\n",
    "\n",
    "    axs[2].plot(history.history['precision'], color='red', label='train')\n",
    "    axs[2].plot(history.history['val_precision'], color='blue', label='val')\n",
    "    axs[2].set_title('Precision ')\n",
    "    axs[2].legend(['train', 'validation'],loc=\"upper right\")\n",
    "\n",
    "    axs[3].plot(history.history['recall'], color='red', label='train')\n",
    "    axs[3].plot(history.history['val_recall'], color='blue', label='val')\n",
    "    axs[3].set_title('Recall')\n",
    "    axs[3].legend(['train', 'validation'],loc=\"upper right\")\n",
    "    \n",
    "\n",
    "    for ax in axs.flat:\n",
    "        ax.set(xlabel='Epoch', ylabel='')\n",
    "\n",
    "    # Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "    for ax in axs.flat:\n",
    "        ax.label_outer()\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_resampled_cat=to_categorical(y_resampled, num_classes=13) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EarlyStopping' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m models_cnn \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# early stopping critera\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m es \u001b[38;5;241m=\u001b[39m \u001b[43mEarlyStopping\u001b[49m(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m init_model()\n\u001b[1;32m     11\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m     12\u001b[0m     X_resampled,\n\u001b[1;32m     13\u001b[0m     y_resampled_cat,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     callbacks \u001b[38;5;241m=\u001b[39m [es]\n\u001b[1;32m     19\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EarlyStopping' is not defined"
     ]
    }
   ],
   "source": [
    "# to save the models & the metrics\n",
    "models_cnn = {}\n",
    "\n",
    "# early stopping critera\n",
    "es = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "\n",
    "    \n",
    "model = init_model()\n",
    "    \n",
    "history = model.fit(\n",
    "    X_resampled,\n",
    "    y_resampled_cat,\n",
    "    validation_data=(X_val, y_val_cat),\n",
    "    epochs = 100,\n",
    "    batch_size = 16, \n",
    "    verbose = 0, \n",
    "    callbacks = [es]\n",
    ")\n",
    "    \n",
    "print(f'------------------------------------------Batch Size {16}------------------------------------------')\n",
    "    \n",
    "# store the model\n",
    "models_cnn[16] = model\n",
    "        \n",
    "# plot the history of loss and accuracy\n",
    "plot_history(history)\n",
    "    \n",
    "# print the evaluation of the model:\n",
    "trainEval = model.evaluate(X_resampled,y_resampled_cat, verbose=0)\n",
    "valEval = model.evaluate(X_val,y_val_cat, verbose=0)\n",
    "\n",
    "print(\"         Model Evaluation on Training :\")\n",
    "print(\"     Training Loss:    \", trainEval[0])\n",
    "print(\"   Training Accuracy:  \", trainEval[1])\n",
    "print(\"  Training Precision:  \", trainEval[2])\n",
    "print(\"    Training Recall:   \", trainEval[3], '\\n')\n",
    "print(\"         Model Evaluation on Validation :\")\n",
    "print(\"    Validation Loss:   \", valEval[0])\n",
    "print(\"  Validation Accuracy: \", valEval[1])\n",
    "print(\" Validation Precision: \", valEval[2])\n",
    "print(\"   Validation Recall:  \", valEval[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
